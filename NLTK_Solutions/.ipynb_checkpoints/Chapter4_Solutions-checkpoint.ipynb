{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11\n",
    "Create a list of words and store it in a variable sent1 . Now assign sent2 = sent1 .\n",
    "Modify one of the items in sent1 and verify that sent2 has changed.\n",
    "- Now try the same exercise but instead assign sent2 = sent1[:] . Modify sent1\n",
    "again and see what happens to sent2 . Explain.\n",
    "- Now define text1 to be a list of lists of strings (e.g. to represent a text consisting of\n",
    "multiple sentences. Now assign text2 = text1[:] , assign a new value to one of the\n",
    "words, e.g. text1[1][1] = 'Monty' . Check what this did to text2 . Explain.\n",
    "- Load Python's deepcopy() function (i.e. from copy import deepcopy ), consult its\n",
    "documentation, and test that it makes a fresh copy of any object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e']\n",
      "['aa', 'b', 'c', 'd', 'e']\n"
     ]
    }
   ],
   "source": [
    "sent1 = list('abcde')\n",
    "sent2 = sent1\n",
    "print(sent2)\n",
    "sent1[0] = 'aa'\n",
    "print(sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e']\n",
      "['a', 'b', 'c', 'd', 'e']\n"
     ]
    }
   ],
   "source": [
    "sent1 = list('abcde')\n",
    "sent2 = sent1[:]\n",
    "print(sent2)\n",
    "sent1[0] = 'aa'\n",
    "print(sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a', 'b', 'c', 'd', 'e'], ['f', 'g', 'h', 'i', 'j']]\n",
      "[['aa', 'b', 'c', 'd', 'e'], ['f', 'g', 'h', 'i', 'j']]\n",
      "[['a', 'b', 'c', 'd', 'e'], ['f', 'g', 'h', 'i', 'j']]\n",
      "[['a', 'b', 'c', 'd', 'e'], ['f', 'g', 'h', 'i', 'j']]\n"
     ]
    }
   ],
   "source": [
    "text1 = [list('abcde'), list('fghij')]\n",
    "text2 = text1[:]\n",
    "print(text2)\n",
    "text1[0][0] = 'aa'\n",
    "print(text2)\n",
    "\n",
    "text1 = [list('abcde'), list('fghij')]\n",
    "text2 = [[i for i in text] for text in text1]\n",
    "print(text2)\n",
    "text1[0][0] = 'aa'\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12\n",
    "Initialize an n-by-m list of lists of empty strings using list multiplication, e.g. word_table\n",
    "= [[''] * n] * m . What happens when you set one of its values, e.g. word_table[1][2]\n",
    "= \"hello\" ? Explain why this happens. Now write an expression using range() to construct\n",
    "a list of lists, and show that it does not have this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['', ''], ['', ''], ['', '']]\n"
     ]
    }
   ],
   "source": [
    "word_table = [[''] * 2] * 3\n",
    "print(word_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_table[0][1] = 'hello'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['', 'hello'], ['', 'hello'], ['', 'hello']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_table = [[\"\" for _ in range(2)] for _ in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['', ''], ['', ''], ['', '']]\n"
     ]
    }
   ],
   "source": [
    "print(word_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['', 'hello'], ['', ''], ['', '']]\n"
     ]
    }
   ],
   "source": [
    "word_table[0][1] = 'hello'\n",
    "print(word_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13\n",
    "Write code to initialize a two-dimensional array of sets called word_vowels and process\n",
    "a list of words, adding each word to word_vowels[l][v] where l is the length of the word\n",
    "and v is the number of vowels it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "words = gutenberg.words('austen-emma.txt')[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 6\n"
     ]
    }
   ],
   "source": [
    "max_len = max([len(word) for word in words])\n",
    "max_vowel = max(([len([char for char in word if char in 'aeiou']) for word in words]))\n",
    "print(max_len, max_vowel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14\n",
    "Write a function novel10(text) that prints any word that appeared in the last 10% of a\n",
    "text that had not been encountered earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def novel10(text):\n",
    "    first = text[:int(len(text)*0.9)]\n",
    "    latter = text[int(len(text)*0.9):]\n",
    "    for word in latter:\n",
    "        if word not in first:\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "words = gutenberg.words('austen-emma.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15\n",
    " Write a program that takes a sentence expressed as a single string, splits it and counts\n",
    "up the words. Get it to print out each word and the word's frequency, one per line, in\n",
    "alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def freq(text):\n",
    "    text = text.split()\n",
    "    fdist = nltk.FreqDist(text)\n",
    "    for word in sorted(fdist.keys()):\n",
    "        print(word, fdist[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "text = gutenberg.raw('austen-emma.txt')[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A 1\n",
      "\"But 1\n",
      "\"How 1\n",
      "\"I 2\n",
      "\"It 1\n",
      "\"My 1\n",
      "\"No, 1\n",
      "\"Not 1\n",
      "\"Poor 1\n",
      "\"The 1\n",
      "\"They 1\n",
      "\"poor 1\n",
      "(and 1\n",
      "1816] 1\n",
      "A 1\n",
      "All 1\n",
      "And 1\n",
      "Austen 1\n",
      "Between 1\n",
      "Brunswick 1\n",
      "But 1\n",
      "CHAPTER 1\n",
      "Christmas 1\n",
      "Emma 7\n",
      "Emma's 1\n",
      "Emma. 1\n",
      "Even 1\n",
      "Hannah 2\n",
      "Hartfield 1\n",
      "Hartfield, 2\n",
      "Hartfield. 1\n",
      "He 5\n",
      "Her 3\n",
      "Highbury, 2\n",
      "His 1\n",
      "How 1\n",
      "I 16\n",
      "Isabella 1\n",
      "Isabella\" 1\n",
      "Isabella's 2\n",
      "It 6\n",
      "James 3\n",
      "James, 1\n",
      "Jane 1\n",
      "Knightley 1\n",
      "Knightley, 2\n",
      "London, 1\n",
      "London. 1\n",
      "Matrimony, 1\n",
      "Miss 12\n",
      "Mr. 12\n",
      "Mrs. 1\n",
      "Nobody 1\n",
      "November 1\n",
      "October 1\n",
      "Randalls 1\n",
      "Randalls, 1\n",
      "She 5\n",
      "Sixteen 1\n",
      "Sorrow 1\n",
      "Square. 1\n",
      "Taylor 10\n",
      "Taylor!--I 1\n",
      "Taylor's 2\n",
      "That 1\n",
      "The 8\n",
      "This 1\n",
      "VOLUME 1\n",
      "We 2\n",
      "Weston 4\n",
      "Weston's 1\n",
      "Weston, 1\n",
      "What 1\n",
      "When 1\n",
      "Whenever 2\n",
      "Woodhouse 3\n",
      "Woodhouse's 1\n",
      "Woodhouse, 1\n",
      "Woodhouses 1\n",
      "You 2\n",
      "[Emma 1\n",
      "_We_ 1\n",
      "_them_ 1\n",
      "a 50\n",
      "able 2\n",
      "about 3\n",
      "absence, 1\n",
      "accepted 1\n",
      "account; 1\n",
      "acquaintance 1\n",
      "activity 1\n",
      "actual 1\n",
      "advantage 1\n",
      "advantages, 1\n",
      "affection 2\n",
      "affection, 1\n",
      "affection. 1\n",
      "affectionate, 1\n",
      "afforded 1\n",
      "afraid 1\n",
      "after 3\n",
      "afterwards 1\n",
      "again. 2\n",
      "age, 1\n",
      "ages 1\n",
      "ago 1\n",
      "agree 1\n",
      "all 12\n",
      "all, 1\n",
      "allowed 1\n",
      "alloy 1\n",
      "almost 1\n",
      "already. 1\n",
      "always 8\n",
      "am 5\n",
      "amiable 1\n",
      "among 1\n",
      "amounting 1\n",
      "amuse 1\n",
      "an 4\n",
      "and 65\n",
      "animated 1\n",
      "answered 1\n",
      "any 7\n",
      "anywhere 1\n",
      "are 3\n",
      "are.\" 1\n",
      "arose, 1\n",
      "as 18\n",
      "asks 1\n",
      "at 9\n",
      "attach 1\n",
      "attached, 1\n",
      "attacked 1\n",
      "authority 1\n",
      "aware 1\n",
      "away, 1\n",
      "awoke, 1\n",
      "back 1\n",
      "backgammon, 1\n",
      "backgammon-table 1\n",
      "bangs 1\n",
      "be 16\n",
      "bear 2\n",
      "beautiful 1\n",
      "because 1\n",
      "been 8\n",
      "before 2\n",
      "begin; 1\n",
      "being 5\n",
      "belong, 1\n",
      "beloved 2\n",
      "best 1\n",
      "between 1\n",
      "beyond 1\n",
      "black 1\n",
      "blessings 1\n",
      "body 1\n",
      "body, 1\n",
      "both 1\n",
      "bride-people 1\n",
      "brother 1\n",
      "brought 2\n",
      "but 14\n",
      "by 9\n",
      "call 1\n",
      "came, 1\n",
      "came--a 1\n",
      "cannot 1\n",
      "cannot. 1\n",
      "caresses; 1\n",
      "carriage! 1\n",
      "carriage, 1\n",
      "ceased 1\n",
      "change 1\n",
      "change, 1\n",
      "change; 1\n",
      "change?--It 1\n",
      "character, 1\n",
      "chatted 1\n",
      "cheer 1\n",
      "cheerful 1\n",
      "cheerful. 1\n",
      "cheerfully 1\n",
      "chiefly 1\n",
      "childhood. 1\n",
      "children 1\n",
      "children, 1\n",
      "circumstance, 1\n",
      "civil, 2\n",
      "clever, 1\n",
      "come 1\n",
      "comfort 1\n",
      "comfortable 1\n",
      "coming 2\n",
      "companion 2\n",
      "comparatively 1\n",
      "compassion, 1\n",
      "composed 1\n",
      "concerns, 1\n",
      "connected 1\n",
      "connexions 1\n",
      "consciousness.--Miss 1\n",
      "consequence 2\n",
      "considering 1\n",
      "constitution 1\n",
      "continuance. 1\n",
      "conversation, 1\n",
      "could 9\n",
      "could, 1\n",
      "curtseys 1\n",
      "daily 1\n",
      "damp 1\n",
      "danger 1\n",
      "danger, 1\n",
      "daughter's 2\n",
      "daughter, 1\n",
      "daughters 1\n",
      "daughters, 1\n",
      "day. 2\n",
      "days' 1\n",
      "deal 1\n",
      "dear, 1\n",
      "dear.\" 1\n",
      "dearer, 1\n",
      "dearly 1\n",
      "debt 1\n",
      "depressed; 1\n",
      "deserves 1\n",
      "devoted 1\n",
      "did 4\n",
      "died 1\n",
      "difference 1\n",
      "differently 1\n",
      "dine 1\n",
      "dinner, 3\n",
      "directed 1\n",
      "directly 1\n",
      "dirt 1\n",
      "disadvantages 1\n",
      "disagreeable 1\n",
      "disagreeable; 1\n",
      "disparity 1\n",
      "disposed 1\n",
      "disposition 1\n",
      "disposition, 1\n",
      "distance. 1\n",
      "distress 1\n",
      "do 1\n",
      "do, 1\n",
      "doing 1\n",
      "doing, 1\n",
      "domestic, 1\n",
      "done 1\n",
      "door 1\n",
      "doubt 1\n",
      "draw 1\n",
      "each 1\n",
      "early 1\n",
      "early) 1\n",
      "easily 1\n",
      "easy 1\n",
      "eight-and-thirty, 1\n",
      "elder 1\n",
      "else. 1\n",
      "enjoyments. 1\n",
      "entirely 1\n",
      "equal 1\n",
      "equals. 1\n",
      "esteeming 1\n",
      "even 1\n",
      "evening 1\n",
      "evening, 1\n",
      "evening. 1\n",
      "event 1\n",
      "ever 3\n",
      "ever, 1\n",
      "every 8\n",
      "everywhere 1\n",
      "evil 1\n",
      "evils, 1\n",
      "exactly 1\n",
      "excellent 3\n",
      "exertions 1\n",
      "existence; 1\n",
      "fallen 1\n",
      "family, 3\n",
      "far.\" 1\n",
      "far? 1\n",
      "father 5\n",
      "father, 1\n",
      "father; 1\n",
      "fault. 1\n",
      "feel 1\n",
      "felt 1\n",
      "few 1\n",
      "fill 1\n",
      "find 1\n",
      "fire.\" 1\n",
      "first 3\n",
      "five 1\n",
      "flow 1\n",
      "followed 1\n",
      "fond 2\n",
      "footing 1\n",
      "for 18\n",
      "fortune, 1\n",
      "found 1\n",
      "frequent 1\n",
      "friend 6\n",
      "friend, 1\n",
      "friend. 1\n",
      "friendliness 1\n",
      "friendship 1\n",
      "from 12\n",
      "generous 1\n",
      "gentle 2\n",
      "gentle, 1\n",
      "get 2\n",
      "girl; 1\n",
      "give 1\n",
      "glad 1\n",
      "go 2\n",
      "goes 1\n",
      "going 3\n",
      "gone, 1\n",
      "good 3\n",
      "good-humoured, 1\n",
      "good; 1\n",
      "got 1\n",
      "governess 1\n",
      "governess, 2\n",
      "gratefully 1\n",
      "gratitude 1\n",
      "great 6\n",
      "grief. 1\n",
      "habits 1\n",
      "habits; 1\n",
      "had 30\n",
      "had, 1\n",
      "half 4\n",
      "handsome, 1\n",
      "happier 2\n",
      "happiness 1\n",
      "happy 2\n",
      "hardly 1\n",
      "hating 2\n",
      "have 13\n",
      "having 2\n",
      "he 10\n",
      "health--and 1\n",
      "hearing 1\n",
      "heart 1\n",
      "help 1\n",
      "her 38\n",
      "her!\" 1\n",
      "her, 1\n",
      "her--James 1\n",
      "her. 6\n",
      "here 2\n",
      "here; 1\n",
      "hers--one 1\n",
      "herself 2\n",
      "herself, 1\n",
      "herself; 1\n",
      "highly 1\n",
      "him 4\n",
      "himself 2\n",
      "himself, 1\n",
      "his 11\n",
      "hold 1\n",
      "home 1\n",
      "hoped, 1\n",
      "horses 2\n",
      "hour 2\n",
      "house 4\n",
      "house, 1\n",
      "house; 1\n",
      "housemaid 1\n",
      "how 5\n",
      "however, 1\n",
      "humours, 2\n",
      "husband, 1\n",
      "husband. 1\n",
      "ideas, 1\n",
      "if 1\n",
      "illnesses 1\n",
      "immediately 1\n",
      "impose 1\n",
      "impossible 2\n",
      "in 27\n",
      "increased 1\n",
      "indeed, 1\n",
      "indistinct 1\n",
      "indulgent 1\n",
      "inquiries 1\n",
      "intellectual 1\n",
      "intelligent, 1\n",
      "intercourse 1\n",
      "interested 2\n",
      "intimacy 1\n",
      "intimate 1\n",
      "into 1\n",
      "is 10\n",
      "it 11\n",
      "it, 2\n",
      "it. 1\n",
      "its 2\n",
      "judgment, 1\n",
      "just 1\n",
      "keep 1\n",
      "kind 1\n",
      "kind. 1\n",
      "kindness, 1\n",
      "kindness--the 1\n",
      "know 2\n",
      "know, 1\n",
      "knowing 1\n",
      "large 2\n",
      "large.--And 1\n",
      "last 2\n",
      "late 2\n",
      "lawn, 1\n",
      "left 2\n",
      "less 1\n",
      "lieu 1\n",
      "life 1\n",
      "life, 1\n",
      "like 2\n",
      "liked; 1\n",
      "little 6\n",
      "live 1\n",
      "lived 2\n",
      "living 1\n",
      "lock 1\n",
      "long 4\n",
      "looked 1\n",
      "loss 1\n",
      "lost. 1\n",
      "loved 1\n",
      "lucky, 1\n",
      "made 2\n",
      "maintain 1\n",
      "make 1\n",
      "man 3\n",
      "man, 2\n",
      "manner, 1\n",
      "manner; 1\n",
      "manners; 1\n",
      "many 4\n",
      "marriage, 2\n",
      "married 1\n",
      "married. 1\n",
      "marrying, 1\n",
      "match 1\n",
      "match; 1\n",
      "matrimony, 1\n",
      "may 1\n",
      "me 1\n",
      "means 2\n",
      "meet 1\n",
      "meeting! 1\n",
      "melancholy 1\n",
      "mentioned 1\n",
      "might 1\n",
      "mild 1\n",
      "mildness 1\n",
      "mile 3\n",
      "miles 1\n",
      "mind 1\n",
      "misfortunes 1\n",
      "mistress 1\n",
      "moonlight 1\n",
      "more 3\n",
      "morning's 1\n",
      "most 2\n",
      "mother 2\n",
      "mournful 1\n",
      "much 5\n",
      "must 8\n",
      "mutual 1\n",
      "mutually 1\n",
      "my 2\n",
      "name, 1\n",
      "natural 1\n",
      "nearly 1\n",
      "necessary 1\n",
      "needlework, 1\n",
      "nervous 1\n",
      "never 4\n",
      "next 1\n",
      "night. 1\n",
      "night; 1\n",
      "no 6\n",
      "nobody 1\n",
      "nominal 1\n",
      "nor 1\n",
      "not 13\n",
      "now 4\n",
      "nursed 1\n",
      "obliged 2\n",
      "observe 1\n",
      "observed, 1\n",
      "odd 2\n",
      "of 63\n",
      "off, 1\n",
      "office 1\n",
      "often 1\n",
      "old 1\n",
      "old--how 1\n",
      "older 1\n",
      "on 2\n",
      "one 1\n",
      "only 6\n",
      "opinion 1\n",
      "or 4\n",
      "origin 1\n",
      "other 1\n",
      "other, 1\n",
      "our 1\n",
      "out 1\n",
      "over 3\n",
      "over, 2\n",
      "owing 1\n",
      "own 2\n",
      "own!--But 1\n",
      "own. 2\n",
      "own? 1\n",
      "own?\" 1\n",
      "papa, 1\n",
      "papa. 2\n",
      "papa; 1\n",
      "part 2\n",
      "particularly 2\n",
      "passed 1\n",
      "past 1\n",
      "pay 1\n",
      "paying 1\n",
      "peculiarly 1\n",
      "people 1\n",
      "perfect 1\n",
      "period. 1\n",
      "pity 1\n",
      "place 1\n",
      "place, 1\n",
      "place. 1\n",
      "placed; 1\n",
      "played 1\n",
      "playful. 1\n",
      "pleasant 2\n",
      "pleasant, 1\n",
      "pleasure, 1\n",
      "poor 3\n",
      "populous 1\n",
      "possessed: 1\n",
      "power 1\n",
      "powers 1\n",
      "present 1\n",
      "pretty 1\n",
      "pretty-spoken 1\n",
      "promise 1\n",
      "promoted 1\n",
      "prospect 1\n",
      "put 2\n",
      "rank 1\n",
      "rather 1\n",
      "rational 1\n",
      "reach; 1\n",
      "real 1\n",
      "really 1\n",
      "recalled 1\n",
      "recollection. 1\n",
      "recommended 1\n",
      "reconciled 1\n",
      "regrets 1\n",
      "remembrance 1\n",
      "removed 1\n",
      "required 1\n",
      "rest 1\n",
      "restraint; 1\n",
      "returned 1\n",
      "rich, 1\n",
      "right 1\n",
      "sad 1\n",
      "said 1\n",
      "sat 1\n",
      "satisfaction 1\n",
      "satisfactorily. 1\n",
      "say 2\n",
      "scheme 1\n",
      "see 4\n",
      "see. 1\n",
      "seemed 1\n",
      "self-denying, 1\n",
      "selfishness, 1\n",
      "sensible 1\n",
      "separate 1\n",
      "servant: 1\n",
      "servant; 1\n",
      "settled 2\n",
      "seven 2\n",
      "shadow 1\n",
      "shall 2\n",
      "shape 1\n",
      "she 21\n",
      "shocking 1\n",
      "short 1\n",
      "shrubberies, 1\n",
      "sigh 1\n",
      "sir. 1\n",
      "sister's 1\n",
      "sister, 1\n",
      "sisters. 1\n",
      "sit 1\n",
      "situation 1\n",
      "sixteen 2\n",
      "sleep 1\n",
      "slighted 1\n",
      "smiled 1\n",
      "so 5\n",
      "society 1\n",
      "solitude. 1\n",
      "some 4\n",
      "somebody 1\n",
      "soon 1\n",
      "soon.\" 1\n",
      "sorrow--but 1\n",
      "spared 1\n",
      "speak 2\n",
      "spent 1\n",
      "spirits 1\n",
      "spite 1\n",
      "stable, 1\n",
      "struggled 1\n",
      "such 6\n",
      "suffering 1\n",
      "suitable 1\n",
      "supplied 1\n",
      "support. 1\n",
      "suppose 1\n",
      "sure 3\n",
      "sure.\" 1\n",
      "take 1\n",
      "talents 1\n",
      "talked 1\n",
      "taught 1\n",
      "tea 1\n",
      "tell 1\n",
      "temper 1\n",
      "temper, 1\n",
      "tenderer 1\n",
      "than 4\n",
      "that 13\n",
      "the 43\n",
      "their 4\n",
      "them 1\n",
      "them, 3\n",
      "them. 1\n",
      "them; 2\n",
      "then 1\n",
      "there 1\n",
      "there. 2\n",
      "these 1\n",
      "they 3\n",
      "thing 1\n",
      "things, 1\n",
      "think 5\n",
      "third 1\n",
      "this 5\n",
      "thoroughly 1\n",
      "though 3\n",
      "thought 5\n",
      "thoughts; 1\n",
      "threatened 1\n",
      "three 1\n",
      "through 3\n",
      "till 2\n",
      "time 1\n",
      "time. 2\n",
      "times 1\n",
      "to 50\n",
      "to, 1\n",
      "together 1\n",
      "together, 1\n",
      "tolerably 1\n",
      "too 3\n",
      "too; 1\n",
      "town, 1\n",
      "true 1\n",
      "turns 1\n",
      "twenty-one 1\n",
      "two 1\n",
      "unexceptionable 1\n",
      "unite 1\n",
      "universally 1\n",
      "unnecessary. 1\n",
      "unperceived, 1\n",
      "unreserve 1\n",
      "up 2\n",
      "upon 2\n",
      "us 2\n",
      "us!--We 1\n",
      "us. 2\n",
      "used 2\n",
      "useful, 1\n",
      "usual, 2\n",
      "valetudinarian 1\n",
      "various 1\n",
      "very 14\n",
      "vex 1\n",
      "village, 1\n",
      "visit 2\n",
      "visit?\" 1\n",
      "visitor 1\n",
      "visitor, 1\n",
      "walk 1\n",
      "walk.\" 1\n",
      "walked 2\n",
      "walking. 1\n",
      "want 1\n",
      "was 35\n",
      "way 1\n",
      "way, 1\n",
      "way;--and 1\n",
      "ways 2\n",
      "we 5\n",
      "wedding 2\n",
      "wedding-day 1\n",
      "welcome 1\n",
      "welcome, 1\n",
      "well 2\n",
      "well-informed, 1\n",
      "were 7\n",
      "what 3\n",
      "when 4\n",
      "where 2\n",
      "whether 1\n",
      "which 5\n",
      "while 1\n",
      "who 3\n",
      "whom 1\n",
      "wife;--and 1\n",
      "will 8\n",
      "wish 2\n",
      "wished 1\n",
      "with 14\n",
      "without 1\n",
      "woman 1\n",
      "work 1\n",
      "world 1\n",
      "would 4\n",
      "years 3\n",
      "years, 1\n",
      "years--how 1\n",
      "years; 1\n",
      "yet 2\n",
      "you 9\n",
      "you!\" 1\n",
      "you, 2\n",
      "youngest 1\n",
      "your 3\n"
     ]
    }
   ],
   "source": [
    "freq(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16\n",
    "Read up on Gematria, a method for assigning numbers to words, and for mapping\n",
    "between words having the same number to discover the hidden meaning of texts\n",
    "( http://en.wikipedia.org/wiki/Gematria , http://essenes.net/gemcal.htm ).\n",
    "- Write a function gematria() that sums the numerical values of the letters of a word,\n",
    "according to the letter values in letter_vals :\n",
    " > letter_vals = {'a':1, 'b':2, 'c':3, 'd':4, 'e':5, 'f':80, 'g':3, 'h':8,\n",
    " 'i':10, 'j':10, 'k':20, 'l':30, 'm':40, 'n':50, 'o':70, 'p':80, 'q':100,\n",
    " 'r':200, 's':300, 't':400, 'u':6, 'v':6, 'w':800, 'x':60, 'y':10, 'z':7}\n",
    "- Process a corpus (e.g. nltk.corpus.state_union ) and for each document, count\n",
    "how many of its words have the number 666.\n",
    "- Write a function decode() to process a text, randomly replacing words with their\n",
    "Gematria equivalents, in order to discover the \"hidden meaning\" of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18\n",
    "Write a function shorten(text, n) to process a text, omitting the n most frequently\n",
    "occurring words of the text. How readable is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def short(text, n):\n",
    "    text_lower = [w.lower() for w in text]\n",
    "    target = [w for w, _ in nltk.FreqDist(text_lower).most_common(n)]\n",
    "    text = [w for w in text if w.lower() not in target]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18\n",
    "Write code to print out an index for a lexicon, allowing someone to look up words\n",
    "according to their meanings (or pronunciations; whatever properties are contained in\n",
    "lexical entries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
