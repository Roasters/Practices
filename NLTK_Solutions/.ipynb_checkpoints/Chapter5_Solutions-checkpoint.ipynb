{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10\n",
    "Train a unigram tagger and run it on some new text. Observe that some words are not\n",
    "assigned a tag. Why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = brown.tagged_sents(categories=\"lore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = nltk.UnigramTagger(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('use', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('high', 'JJ'),\n",
       " ('voltages', None),\n",
       " ('and', 'CC'),\n",
       " ('low', 'JJ'),\n",
       " ('currents', None),\n",
       " ('by', 'IN'),\n",
       " ('proper', 'JJ'),\n",
       " ('design', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('reduce', 'VB'),\n",
       " ('electron', None),\n",
       " ('heat', 'NN'),\n",
       " ('transfer', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'AT'),\n",
       " ('anode', None),\n",
       " ('for', 'IN'),\n",
       " ('a', 'AT'),\n",
       " ('given', 'VBN'),\n",
       " ('power', 'NN'),\n",
       " ('output', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag(brown.sents(categories=\"learned\")[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11\n",
    "Learn about the affix tagger (type help(nltk.AffixTagger)). Train an affix tagger and\n",
    "run it on some new text. Experiment with different settings for the affix length and the\n",
    "minimum word length. Discuss your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class AffixTagger in module nltk.tag.sequential:\n",
      "\n",
      "class AffixTagger(ContextTagger)\n",
      " |  AffixTagger(train=None, model=None, affix_length=-3, min_stem_length=2, backoff=None, cutoff=0, verbose=False)\n",
      " |  \n",
      " |  A tagger that chooses a token's tag based on a leading or trailing\n",
      " |  substring of its word string.  (It is important to note that these\n",
      " |  substrings are not necessarily \"true\" morphological affixes).  In\n",
      " |  particular, a fixed-length substring of the word is looked up in a\n",
      " |  table, and the corresponding tag is returned.  Affix taggers are\n",
      " |  typically constructed by training them on a tagged corpus.\n",
      " |  \n",
      " |  Construct a new affix tagger.\n",
      " |  \n",
      " |  :param affix_length: The length of the affixes that should be\n",
      " |      considered during training and tagging.  Use negative\n",
      " |      numbers for suffixes.\n",
      " |  :param min_stem_length: Any words whose length is less than\n",
      " |      min_stem_length+abs(affix_length) will be assigned a\n",
      " |      tag of None by this tagger.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      AffixTagger\n",
      " |      ContextTagger\n",
      " |      SequentialBackoffTagger\n",
      " |      nltk.tag.api.TaggerI\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, train=None, model=None, affix_length=-3, min_stem_length=2, backoff=None, cutoff=0, verbose=False)\n",
      " |      :param context_to_tag: A dictionary mapping contexts to tags.\n",
      " |      :param backoff: The backoff tagger that should be used for this tagger.\n",
      " |  \n",
      " |  context(self, tokens, index, history)\n",
      " |      :return: the context that should be used to look up the tag\n",
      " |          for the specified token; or None if the specified token\n",
      " |          should not be handled by this tagger.\n",
      " |      :rtype: (hashable)\n",
      " |  \n",
      " |  encode_json_obj(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  decode_json_obj(obj) from abc.ABCMeta\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  json_tag = 'nltk.tag.sequential.AffixTagger'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ContextTagger:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __unicode__ = __str__(self, /)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  choose_tag(self, tokens, index, history)\n",
      " |      Decide which tag should be used for the specified token, and\n",
      " |      return that tag.  If this tagger is unable to determine a tag\n",
      " |      for the specified token, return None -- do not consult\n",
      " |      the backoff tagger.  This method should be overridden by\n",
      " |      subclasses of SequentialBackoffTagger.\n",
      " |      \n",
      " |      :rtype: str\n",
      " |      :type tokens: list\n",
      " |      :param tokens: The list of words that are being tagged.\n",
      " |      :type index: int\n",
      " |      :param index: The index of the word whose tag should be\n",
      " |          returned.\n",
      " |      :type history: list(str)\n",
      " |      :param history: A list of the tags for all words before *index*.\n",
      " |  \n",
      " |  size(self)\n",
      " |      :return: The number of entries in the table used by this\n",
      " |          tagger to map from contexts to tags.\n",
      " |  \n",
      " |  unicode_repr = __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from SequentialBackoffTagger:\n",
      " |  \n",
      " |  tag(self, tokens)\n",
      " |      Determine the most appropriate tag sequence for the given\n",
      " |      token sequence, and return a corresponding list of tagged\n",
      " |      tokens.  A tagged token is encoded as a tuple ``(token, tag)``.\n",
      " |      \n",
      " |      :rtype: list(tuple(str, str))\n",
      " |  \n",
      " |  tag_one(self, tokens, index, history)\n",
      " |      Determine an appropriate tag for the specified token, and\n",
      " |      return that tag.  If this tagger is unable to determine a tag\n",
      " |      for the specified token, then its backoff tagger is consulted.\n",
      " |      \n",
      " |      :rtype: str\n",
      " |      :type tokens: list\n",
      " |      :param tokens: The list of words that are being tagged.\n",
      " |      :type index: int\n",
      " |      :param index: The index of the word whose tag should be\n",
      " |          returned.\n",
      " |      :type history: list(str)\n",
      " |      :param history: A list of the tags for all words before *index*.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from SequentialBackoffTagger:\n",
      " |  \n",
      " |  backoff\n",
      " |      The backoff tagger for this tagger.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from nltk.tag.api.TaggerI:\n",
      " |  \n",
      " |  evaluate(self, gold)\n",
      " |      Score the accuracy of the tagger against the gold standard.\n",
      " |      Strip the tags from the gold standard text, retag it using\n",
      " |      the tagger, then compute the accuracy score.\n",
      " |      \n",
      " |      :type gold: list(list(tuple(str, str)))\n",
      " |      :param gold: The list of tagged sentences to score the tagger on.\n",
      " |      :rtype: float\n",
      " |  \n",
      " |  tag_sents(self, sentences)\n",
      " |      Apply ``self.tag()`` to each element of *sentences*.  I.e.:\n",
      " |      \n",
      " |          return [self.tag(sent) for sent in sentences]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from nltk.tag.api.TaggerI:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nltk.AffixTagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14\n",
    "Use sorted() and set() to get a sorted list of tags used in the Brown corpus, removing\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'\", \"''\", '(', '(-HL', ')', ')-HL', '*', '*-HL', ',', ',-HL', '--', '.', '.-HL', ':', ':-HL', 'ABL', 'ABN', 'ABN-HL', 'ABX', 'AP', 'AP$', 'AP-HL', 'AP-TL', 'AT', 'AT-HL', 'AT-TL', 'BE', 'BE-HL', 'BED', 'BED*', 'BEDZ', 'BEDZ*', 'BEDZ-HL', 'BEG', 'BEM', 'BEN', 'BER', 'BER*', 'BER-HL', 'BER-TL', 'BEZ', 'BEZ*', 'BEZ-HL', 'CC', 'CC-HL', 'CC-TL', 'CD', 'CD$', 'CD-HL', 'CD-TL', 'CS', 'CS-HL', 'DO', 'DO*', 'DO-HL', 'DOD', 'DOD*', 'DOZ', 'DOZ*', 'DT', 'DT$', 'DT+BEZ', 'DT-HL', 'DTI', 'DTI-HL', 'DTS', 'DTX', 'EX', 'EX+BEZ', 'FW-*', 'FW-AT', 'FW-AT-HL', 'FW-AT-TL', 'FW-CC', 'FW-CD', 'FW-DT', 'FW-IN', 'FW-IN+AT-TL', 'FW-IN+NN', 'FW-IN+NN-TL', 'FW-IN-TL', 'FW-JJ', 'FW-JJ-TL', 'FW-NN', 'FW-NN-TL', 'FW-NNS', 'FW-PP$-NC', 'FW-VB', 'FW-VB-NC', 'FW-WDT', 'HV', 'HVD', 'HVD*', 'HVD-HL', 'HVG', 'HVN', 'HVZ', 'HVZ*', 'IN', 'IN-HL', 'IN-TL', 'JJ', 'JJ-HL', 'JJ-NC', 'JJ-TL', 'JJR', 'JJR-HL', 'JJR-NC', 'JJR-TL', 'JJS', 'JJS-TL', 'JJT', 'JJT-HL', 'MD', 'MD*', 'MD*-HL', 'MD+HV', 'MD-HL', 'MD-TL', 'NN', 'NN$', 'NN$-HL', 'NN$-TL', 'NN-HL', 'NN-NC', 'NN-TL', 'NN-TL-HL', 'NNS', 'NNS$', 'NNS$-HL', 'NNS$-TL', 'NNS-HL', 'NNS-TL', 'NNS-TL-HL', 'NP', 'NP$', 'NP$-TL', 'NP+BEZ', 'NP-HL', 'NP-TL', 'NP-TL-HL', 'NPS', 'NPS$', 'NPS$-TL', 'NPS-HL', 'NPS-TL', 'NR', 'NR$', 'NR$-TL', 'NR-HL', 'NR-TL', 'OD', 'OD-HL', 'OD-TL', 'PN', 'PN$', 'PN+HVZ', 'PN-HL', 'PP$', 'PP$$', 'PP$-TL', 'PPL', 'PPLS', 'PPO', 'PPS', 'PPS+BEZ', 'PPS+BEZ-HL', 'PPS+HVZ', 'PPS+MD', 'PPSS', 'PPSS+BEM', 'PPSS+BER', 'PPSS+HV', 'PPSS+HVD', 'PPSS+MD', 'PPSS-HL', 'QL', 'QL-TL', 'QLP', 'RB', 'RB$', 'RB+BEZ', 'RB-HL', 'RB-TL', 'RBR', 'RBT', 'RP', 'RP-HL', 'TO', 'TO-HL', 'TO-TL', 'UH', 'UH-TL', 'VB', 'VB+PPO', 'VB-HL', 'VB-TL', 'VBD', 'VBD-HL', 'VBD-TL', 'VBG', 'VBG-HL', 'VBG-TL', 'VBN', 'VBN-HL', 'VBN-TL', 'VBN-TL-HL', 'VBZ', 'VBZ-HL', 'WDT', 'WDT+BEZ', 'WP$', 'WPO', 'WPS', 'WPS+BEZ', 'WQL', 'WRB', '``']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(set(t for w, t in brown.tagged_words(categories='news'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15\n",
    "Write programs to process the Brown Corpus and find answers to the following\n",
    "questions:\n",
    "1. Which nouns are more common in their plural form, rather than their singular\n",
    "form? (Only consider regular plurals, formed with the -s suffix.)\n",
    "2. Which word has the greatest number of distinct tags. What are they, and what do\n",
    "they represent?\n",
    "3. List tags in order of decreasing frequency. What do the 20 most frequent tags\n",
    "represent?\n",
    "4. Which tags are nouns most commonly found after? What do these tags represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fan                  | Plural: 3 | Singular: 2\n",
      "spectator            | Plural: 5 | Singular: 2\n",
      "commitment           | Plural: 3 | Singular: 2\n",
      "call                 | Plural: 7 | Singular: 4\n",
      "method               | Plural: 10 | Singular: 3\n",
      "twin                 | Plural: 3 | Singular: 2\n",
      "outsider             | Plural: 2 | Singular: 1\n",
      "acre                 | Plural: 10 | Singular: 2\n",
      "fee                  | Plural: 13 | Singular: 7\n",
      "design               | Plural: 10 | Singular: 6\n",
      "official             | Plural: 14 | Singular: 6\n",
      "restriction          | Plural: 3 | Singular: 1\n",
      "language             | Plural: 3 | Singular: 2\n",
      "arrangement          | Plural: 4 | Singular: 2\n",
      "destroyer            | Plural: 2 | Singular: 1\n",
      "sport                | Plural: 10 | Singular: 2\n",
      "talk                 | Plural: 7 | Singular: 3\n",
      "shade                | Plural: 2 | Singular: 1\n",
      "soldier              | Plural: 2 | Singular: 1\n",
      "trustee              | Plural: 5 | Singular: 1\n",
      "raise                | Plural: 3 | Singular: 1\n",
      "grant                | Plural: 13 | Singular: 5\n",
      "adviser              | Plural: 7 | Singular: 3\n",
      "underwriter          | Plural: 2 | Singular: 1\n",
      "vow                  | Plural: 2 | Singular: 1\n",
      "pain                 | Plural: 2 | Singular: 1\n",
      "product              | Plural: 16 | Singular: 10\n",
      "bond                 | Plural: 29 | Singular: 11\n",
      "officer              | Plural: 18 | Singular: 9\n",
      "passenger            | Plural: 3 | Singular: 2\n",
      "quota                | Plural: 3 | Singular: 1\n",
      "error                | Plural: 8 | Singular: 2\n",
      "mile                 | Plural: 10 | Singular: 5\n",
      "letter               | Plural: 13 | Singular: 7\n",
      "endowment            | Plural: 2 | Singular: 1\n",
      "payment              | Plural: 9 | Singular: 7\n",
      "mechanic             | Plural: 2 | Singular: 1\n",
      "change               | Plural: 12 | Singular: 6\n",
      "representative       | Plural: 7 | Singular: 6\n",
      "technique            | Plural: 2 | Singular: 1\n",
      "flower               | Plural: 4 | Singular: 2\n",
      "rebel                | Plural: 3 | Singular: 2\n",
      "owner                | Plural: 11 | Singular: 3\n",
      "share                | Plural: 19 | Singular: 10\n",
      "motion               | Plural: 4 | Singular: 2\n",
      "manufacturer         | Plural: 10 | Singular: 5\n",
      "string               | Plural: 5 | Singular: 1\n",
      "tone                 | Plural: 2 | Singular: 1\n",
      "second               | Plural: 2 | Singular: 1\n",
      "material             | Plural: 3 | Singular: 2\n",
      "taxpayer             | Plural: 5 | Singular: 3\n",
      "month                | Plural: 42 | Singular: 32\n",
      "comment              | Plural: 3 | Singular: 2\n",
      "librarian            | Plural: 5 | Singular: 4\n",
      "truck                | Plural: 6 | Singular: 2\n",
      "narcotic             | Plural: 6 | Singular: 1\n",
      "bird                 | Plural: 10 | Singular: 2\n",
      "adjustment           | Plural: 2 | Singular: 1\n",
      "shareholder          | Plural: 2 | Singular: 1\n",
      "pool                 | Plural: 4 | Singular: 1\n",
      "hat                  | Plural: 3 | Singular: 2\n",
      "student              | Plural: 24 | Singular: 21\n",
      "prospect             | Plural: 7 | Singular: 5\n",
      "appeal               | Plural: 10 | Singular: 3\n",
      "employer             | Plural: 4 | Singular: 2\n",
      "dollar               | Plural: 15 | Singular: 6\n",
      "competitor           | Plural: 2 | Singular: 1\n",
      "cookie               | Plural: 3 | Singular: 2\n",
      "sale                 | Plural: 52 | Singular: 8\n",
      "poster               | Plural: 2 | Singular: 1\n",
      "person               | Plural: 25 | Singular: 11\n",
      "worker               | Plural: 17 | Singular: 2\n",
      "abuse                | Plural: 2 | Singular: 1\n",
      "red                  | Plural: 3 | Singular: 1\n",
      "grip                 | Plural: 2 | Singular: 1\n",
      "rule                 | Plural: 20 | Singular: 18\n",
      "aide                 | Plural: 3 | Singular: 1\n",
      "employee             | Plural: 11 | Singular: 1\n",
      "cardinal             | Plural: 4 | Singular: 1\n",
      "reform               | Plural: 4 | Singular: 3\n",
      "painting             | Plural: 5 | Singular: 1\n",
      "observer             | Plural: 2 | Singular: 1\n",
      "run                  | Plural: 30 | Singular: 20\n",
      "detail               | Plural: 3 | Singular: 2\n",
      "obligation           | Plural: 4 | Singular: 1\n",
      "professor            | Plural: 3 | Singular: 1\n",
      "banker               | Plural: 11 | Singular: 1\n",
      "good                 | Plural: 5 | Singular: 3\n",
      "newspaper            | Plural: 2 | Singular: 1\n",
      "friend               | Plural: 13 | Singular: 2\n",
      "visitor              | Plural: 2 | Singular: 1\n",
      "draft                | Plural: 2 | Singular: 1\n",
      "procedure            | Plural: 5 | Singular: 2\n",
      "citizen              | Plural: 11 | Singular: 1\n",
      "drum                 | Plural: 4 | Singular: 2\n",
      "picker               | Plural: 3 | Singular: 1\n",
      "stroke               | Plural: 8 | Singular: 6\n",
      "revenue              | Plural: 13 | Singular: 8\n",
      "farmer               | Plural: 8 | Singular: 3\n",
      "piece                | Plural: 7 | Singular: 3\n",
      "janitor              | Plural: 2 | Singular: 1\n",
      "chair                | Plural: 4 | Singular: 1\n",
      "minute               | Plural: 25 | Singular: 1\n",
      "application          | Plural: 4 | Singular: 2\n",
      "weapon               | Plural: 6 | Singular: 1\n",
      "roommate             | Plural: 2 | Singular: 1\n",
      "hour                 | Plural: 23 | Singular: 17\n",
      "nerve                | Plural: 2 | Singular: 1\n",
      "builder              | Plural: 9 | Singular: 1\n",
      "duffer               | Plural: 2 | Singular: 1\n",
      "decoration           | Plural: 2 | Singular: 1\n",
      "artist               | Plural: 5 | Singular: 4\n",
      "completion           | Plural: 3 | Singular: 2\n",
      "detective            | Plural: 6 | Singular: 2\n",
      "affair               | Plural: 11 | Singular: 6\n",
      "dealer               | Plural: 10 | Singular: 5\n",
      "reporter             | Plural: 4 | Singular: 2\n",
      "allowance            | Plural: 3 | Singular: 2\n",
      "element              | Plural: 3 | Singular: 2\n",
      "rifle                | Plural: 2 | Singular: 1\n",
      "puppet               | Plural: 5 | Singular: 4\n",
      "step                 | Plural: 8 | Singular: 7\n",
      "aspect               | Plural: 5 | Singular: 4\n",
      "musician             | Plural: 3 | Singular: 1\n",
      "wage                 | Plural: 11 | Singular: 2\n",
      "yard                 | Plural: 23 | Singular: 1\n",
      "organ                | Plural: 2 | Singular: 1\n",
      "scholarship          | Plural: 4 | Singular: 3\n",
      "arm                  | Plural: 11 | Singular: 2\n",
      "machine              | Plural: 7 | Singular: 5\n",
      "hit                  | Plural: 11 | Singular: 5\n",
      "chore                | Plural: 4 | Singular: 1\n",
      "implement            | Plural: 3 | Singular: 1\n",
      "price                | Plural: 19 | Singular: 14\n",
      "height               | Plural: 3 | Singular: 1\n",
      "longhorn             | Plural: 4 | Singular: 2\n",
      "resident             | Plural: 6 | Singular: 2\n",
      "intention            | Plural: 6 | Singular: 4\n",
      "sculpture            | Plural: 3 | Singular: 1\n",
      "player               | Plural: 13 | Singular: 7\n",
      "appearance           | Plural: 3 | Singular: 2\n",
      "feature              | Plural: 2 | Singular: 1\n",
      "bridge               | Plural: 2 | Singular: 1\n",
      "gain                 | Plural: 8 | Singular: 6\n",
      "individual           | Plural: 5 | Singular: 4\n",
      "writer               | Plural: 5 | Singular: 3\n",
      "teamster             | Plural: 5 | Singular: 1\n",
      "obstacle             | Plural: 2 | Singular: 1\n",
      "correspondent        | Plural: 2 | Singular: 1\n",
      "king                 | Plural: 4 | Singular: 3\n",
      "decorator            | Plural: 3 | Singular: 1\n",
      "defendant            | Plural: 9 | Singular: 3\n",
      "ga                   | Plural: 10 | Singular: 1\n",
      "relationship         | Plural: 2 | Singular: 1\n",
      "seat                 | Plural: 5 | Singular: 3\n",
      "pirate               | Plural: 9 | Singular: 2\n",
      "tank                 | Plural: 2 | Singular: 1\n",
      "wood                 | Plural: 4 | Singular: 1\n",
      "master               | Plural: 10 | Singular: 5\n",
      "institution          | Plural: 10 | Singular: 8\n",
      "voter                | Plural: 13 | Singular: 2\n",
      "peddler              | Plural: 2 | Singular: 1\n",
      "dancer               | Plural: 4 | Singular: 2\n",
      "troop                | Plural: 10 | Singular: 2\n",
      "estimate             | Plural: 4 | Singular: 2\n",
      "princes              | Plural: 4 | Singular: 1\n",
      "pitcher              | Plural: 5 | Singular: 4\n",
      "rate                 | Plural: 9 | Singular: 7\n",
      "path                 | Plural: 2 | Singular: 1\n",
      "parent               | Plural: 6 | Singular: 1\n",
      "recommendation       | Plural: 6 | Singular: 1\n",
      "hoodlum              | Plural: 2 | Singular: 1\n",
      "force                | Plural: 16 | Singular: 14\n",
      "snack                | Plural: 2 | Singular: 1\n",
      "pocket               | Plural: 2 | Singular: 1\n",
      "legislator           | Plural: 11 | Singular: 2\n",
      "standard             | Plural: 4 | Singular: 2\n",
      "contribution         | Plural: 9 | Singular: 4\n",
      "cleaner              | Plural: 2 | Singular: 1\n",
      "member               | Plural: 74 | Singular: 35\n",
      "signature            | Plural: 5 | Singular: 1\n",
      "fund                 | Plural: 29 | Singular: 19\n",
      "mistake              | Plural: 2 | Singular: 1\n",
      "resource             | Plural: 6 | Singular: 1\n",
      "lieutenant           | Plural: 2 | Singular: 1\n",
      "golfer               | Plural: 4 | Singular: 2\n",
      "nation               | Plural: 25 | Singular: 13\n",
      "item                 | Plural: 4 | Singular: 1\n",
      "motorist             | Plural: 4 | Singular: 2\n",
      "toy                  | Plural: 6 | Singular: 1\n",
      "investor             | Plural: 11 | Singular: 1\n",
      "tribe                | Plural: 4 | Singular: 1\n",
      "store                | Plural: 4 | Singular: 3\n",
      "folk                 | Plural: 2 | Singular: 1\n",
      "cost                 | Plural: 18 | Singular: 14\n",
      "guest                | Plural: 18 | Singular: 6\n",
      "negotiation          | Plural: 11 | Singular: 1\n",
      "neighbor             | Plural: 6 | Singular: 5\n"
     ]
    }
   ],
   "source": [
    "tagged_words = [(w.lower(), t) for w, t in brown.tagged_words(categories='news')]\n",
    "nouns = [w for w, t in tagged_words if t.startswith('NN')]\n",
    "fdist = nltk.FreqDist(nouns)\n",
    "for w in set(nouns):\n",
    "    if fdist[w+'s'] > fdist[w]:\n",
    "        print(\"{:<20}\".format(w), \"| Plural:\", fdist[w+'s'], \"| Singular:\", fdist[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no ['AT', 'RB', 'AT-HL', 'AT-TL'] 4\n",
      "that ['CS', 'WPS', 'DT', 'QL', 'WPO'] 5\n",
      "place ['NN', 'VB', 'NN-TL', 'NP'] 4\n",
      "in ['IN', 'RP', 'IN-HL', 'IN-TL'] 4\n",
      "for ['IN', 'IN-TL', 'IN-HL', 'CS', 'RB'] 5\n",
      "by ['IN', 'IN-HL', 'IN-TL', 'RB'] 4\n",
      "to ['TO', 'IN', 'IN-HL', 'TO-HL', 'IN-TL', 'TO-TL', 'NPS'] 7\n",
      "only ['RB', 'AP', 'JJ', 'QL'] 4\n",
      "a ['AT', 'AT-HL', 'NN', 'AT-TL', 'FW-IN'] 5\n",
      "act ['VB', 'NN', 'NN-TL', 'NN-HL'] 4\n",
      "end ['NN', 'VB', 'NN-TL', 'NN-HL'] 4\n",
      "on ['IN', 'IN-TL', 'RP', 'IN-HL'] 4\n",
      "best ['JJT', 'RBT', 'JJT-HL', 'VB', 'NP-TL'] 5\n",
      "cost ['NN', 'NN-HL', 'VB', 'VBD'] 4\n",
      "as ['CS', 'IN', 'QL', 'CS-HL'] 4\n",
      "major ['JJ', 'NN-TL', 'NP', 'NN'] 4\n",
      "general ['JJ', 'NN', 'JJ-TL', 'NN-TL'] 4\n",
      "fair ['JJ', 'NN', 'JJ-HL', 'NN-TL', 'JJ-TL'] 5\n",
      "plan ['NN', 'VB', 'NN-HL', 'NN-TL'] 4\n",
      "police ['NNS-TL', 'NN', 'NNS', 'NNS-HL'] 4\n",
      "more ['AP', 'AP-HL', 'QL', 'RBR'] 4\n",
      "home ['NR', 'NN', 'NN-HL', 'NN-TL', 'NR-HL', 'NP'] 6\n",
      "back ['RB', 'VB', 'NN', 'RB-HL', 'RB-TL'] 5\n",
      "present ['JJ', 'RB', 'NN', 'VB'] 4\n",
      "held ['VBN', 'VBD', 'VBN-HL', 'VBD-HL'] 4\n",
      "force ['VB', 'NN-TL', 'NN', 'FW-NN-TL'] 4\n",
      "out ['RP', 'IN', 'PP$', 'RP-HL'] 4\n",
      "first ['OD', 'RB', 'OD-HL', 'RB-HL', 'OD-TL'] 5\n",
      "must ['MD', 'MD-HL', 'MD-TL', 'NN'] 4\n",
      "issue ['NN', 'VB', 'VB-HL', 'NN-HL'] 4\n",
      "near ['RB', 'RB-HL', 'JJ', 'IN', 'QL'] 5\n",
      "most ['QL', 'AP', 'RBT', 'QL-TL'] 4\n",
      "house ['NN-TL', 'NN', 'NN-HL', 'NP-TL-HL', 'NP', 'NN-TL-HL', 'VB'] 7\n",
      "increase ['NN', 'VB', 'VB-HL', 'NN-HL'] 4\n",
      "set ['VB', 'VBN', 'VBD', 'VBN-HL', 'NN'] 5\n",
      "last ['AP', 'AP-TL', 'VB', 'NN', 'AP-HL'] 5\n",
      "past ['NN', 'JJ', 'AP', 'IN'] 4\n",
      "like ['VB', 'CS', 'IN', 'JJ', 'VB-HL'] 5\n",
      "read ['VBN', 'VBD', 'NP', 'VB'] 4\n",
      "march ['NP', 'NN', 'NP-HL', 'NN-TL', 'VB'] 5\n",
      "post ['NN', 'VB', 'NP', 'NN-TL'] 4\n",
      "good ['JJ', 'NN', 'JJ-TL', 'RB', 'JJ-HL'] 5\n",
      "down ['RP', 'IN', 'RP-HL', 'NP-TL'] 4\n",
      "left ['VBD', 'VBN', 'JJ', 'NR'] 4\n",
      "little ['AP', 'JJ', 'QL', 'NP', 'JJ-TL'] 5\n",
      "help ['VB', 'NN', 'NN-HL', 'VB-HL'] 4\n",
      "report ['VB', 'NN', 'VB-HL', 'NN-TL'] 4\n",
      "red ['NP', 'JJ-TL', 'NN-TL', 'JJ'] 4\n",
      "better ['RBR', 'VB', 'JJR', 'JJR-TL', 'QL'] 5\n",
      "fine ['NN', 'JJ', 'JJ-TL', 'RB'] 4\n",
      "right ['NN', 'JJ', 'RB', 'QL'] 4\n",
      "3 ['CD-TL', 'CD', 'CD-HL', 'OD', 'OD-TL'] 5\n",
      "chief ['JJS', 'JJS-TL', 'NN', 'NN-TL'] 4\n",
      "high ['JJ', 'NN', 'JJ-TL', 'JJ-HL', 'RB'] 5\n",
      "close ['NN', 'JJ', 'RB', 'VB'] 4\n",
      "cook ['NP', 'NP-TL', 'NN', 'VB'] 4\n",
      "case ['NN', 'NP', 'NN-HL', 'NP-TL'] 4\n",
      "grant ['VB', 'NN', 'NP', 'VB-HL'] 4\n",
      "white ['JJ-TL', 'NN-TL', 'NP', 'JJ', 'NN'] 5\n",
      "even ['QL', 'RB', 'JJ', 'VB'] 4\n",
      "st. ['NP-TL', 'NN-TL', 'NP', 'NP-HL'] 4\n",
      "reading ['VBG', 'NN', 'NN-HL', 'NP'] 4\n",
      "hill ['NN-TL', 'NN-HL', 'NP', 'NN'] 4\n",
      "cut ['VBN', 'VB', 'VBD', 'NN-HL', 'NN'] 5\n",
      "field ['NN', 'NN-TL', 'VB', 'NP'] 4\n",
      "met ['VBN', 'NP-HL', 'NP', 'VBD'] 4\n",
      "half ['ABN', 'RB', 'NN', 'QL'] 4\n",
      "point ['NN', 'NN-HL', 'NN-TL', 'VB'] 4\n",
      "open ['JJ', 'RB', 'VB', 'NN-TL', 'NN'] 5\n",
      "green ['JJ-TL', 'JJ', 'NP', 'NN'] 4\n",
      "works ['NNS', 'NNS-TL', 'VBZ', 'NNS-HL'] 4\n",
      "round ['NN', 'VB', 'JJ', 'NN-TL'] 4\n",
      "second ['OD', 'NN', 'RB', 'QL', 'OD-TL'] 5\n",
      "beat ['VBD', 'VB', 'NN-TL-HL', 'NN'] 4\n",
      "hit ['NN', 'VBN', 'VB', 'VBD', 'NN-HL'] 5\n",
      "brown ['NP', 'NP-TL', 'JJ', 'NN'] 4\n",
      "lay ['VBD', 'JJ', 'NP', 'VB'] 4\n",
      "gold ['JJ-TL', 'JJ', 'NN-TL', 'NN'] 4\n",
      "mother ['NN', 'VB', 'NN-TL', 'NN-HL'] 4\n",
      "swim ['NN', 'VB', 'NP-HL', 'NP'] 4\n",
      "french ['JJ', 'NP', 'JJ-HL', 'JJ-TL', 'NPS'] 5\n",
      "ballet ['FW-NN-TL', 'NN-TL', 'NN', 'FW-NN'] 4\n",
      "congolese ['JJ', 'NPS', 'NP', 'JJ-TL'] 4\n"
     ]
    }
   ],
   "source": [
    "cfd = nltk.ConditionalFreqDist(tagged_words)\n",
    "for word in cfd.conditions():\n",
    "    if len(cfd[word]) > 3:\n",
    "        print(word, list(cfd[word]), len(cfd[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NN', 13162), ('IN', 10616), ('AT', 8893), ('NP', 6866), (',', 5133), ('NNS', 5066), ('.', 4452), ('JJ', 4392), ('CC', 2664), ('VBD', 2524), ('NN-TL', 2486), ('VB', 2440), ('VBN', 2269), ('RB', 2166), ('CD', 2020), ('CS', 1509), ('VBG', 1398), ('TO', 1237), ('PPS', 1056), ('PP$', 1051)]\n"
     ]
    }
   ],
   "source": [
    "tags = [t for w, t in tagged_words]\n",
    "print(nltk.FreqDist(tags).most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AT      5194\n",
      "JJ      2996\n",
      "NN      2180\n",
      "IN      1928\n",
      "CD      785\n",
      "NN-TL   776\n",
      "PP$     719\n",
      "AP      518\n",
      "CC      506\n",
      "NP-TL   466\n",
      "NP      461\n",
      ".       441\n",
      ",       441\n",
      "JJ-TL   426\n",
      "VBG     379\n",
      "DT      323\n",
      "VBN     291\n",
      "VB      248\n",
      "OD      159\n",
      "VBD     157\n"
     ]
    }
   ],
   "source": [
    "tag_before_NN = [t1 for (w1, t1), (w2, t2) in nltk.bigrams(tagged_words) if t2.startswith('NN')]\n",
    "for t, n in nltk.FreqDist(tag_before_NN).most_common(20):\n",
    "    print(\"{:<8}{:}\".format(t, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16\n",
    "Explore the following issues that arise in connection with the lookup tagger:\n",
    "1. What happens to the tagger performance for the various model sizes when a\n",
    "backoff tagger is omitted?\n",
    "2. Consider the curve in 4.2; suggest a good size for a lookup tagger that balances\n",
    "memory and performance. Can you come up with scenarios where it would be\n",
    "preferable to minimize memory usage, or to maximize performance with no\n",
    "regard for memory usage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17\n",
    "What is the upper limit of performance for a lookup tagger, assuming no limit to the\n",
    "size of its table? (Hint: write a program to work out what percentage of tokens of a word\n",
    "are assigned the most likely tag for that word, on average.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31390207293821754\n"
     ]
    }
   ],
   "source": [
    "tagged_words = brown.tagged_words(categories=\"learned\")\n",
    "tagged_words = [(w.lower(), t) for w, t in tagged_words]\n",
    "cfd = nltk.ConditionalFreqDist(tagged_words)\n",
    "print(len(cfd)/sum([len(tags) for word in cfd.conditions() for tags in cfd[word]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18\n",
    " Generate some statistics for tagged data to answer the following questions:\n",
    "1. What proportion of word types are always assigned the same part-of-speech tag?\n",
    "2. How many words are ambiguous, in the sense that they appear with at least two\n",
    "tags?\n",
    "3. What percentage of word tokens in the Brown Corpus involve these ambiguous\n",
    "words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8348078096400244\n"
     ]
    }
   ],
   "source": [
    "tagged_words = brown.tagged_words(categories=\"news\")\n",
    "tagged_words = [(w.lower(), t) for w, t in tagged_words]\n",
    "cfd = nltk.ConditionalFreqDist(tagged_words)\n",
    "print(len([w for w in cfd.conditions() if len(cfd[w]) == 1]) / len(cfd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1651921903599756\n"
     ]
    }
   ],
   "source": [
    "print(len([w for w in cfd.conditions() if len(cfd[w]) >= 2]) / len(cfd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19\n",
    "The evaluate() method works out how accurately the tagger performs on this text. For\n",
    "example, if the supplied tagged text was [( 'the' , 'DT' ), ( 'dog' , 'NN' )] and the tagger\n",
    "produced the output [( 'the' , 'NN' ), ( 'dog' , 'NN' )], then the score would be 0.5. Let's\n",
    "try to figure out how the evaluation method works:\n",
    "1. A tagger t takes a list of words as input, and produces a list of tagged words as\n",
    "output. However, t.evaluate() is given correctly tagged text as its only parameter.\n",
    "What must it do with this input before performing the tagging?\n",
    "2. Once the tagger has created newly tagged text, how might the evaluate() method\n",
    "go about comparing it with the original tagged text and computing the accuracy\n",
    "score?\n",
    "3. Now examine the source code to see how the method is implemented. Inspect\n",
    "nltk.tag.api.__file__ to discover the location of the source code, and open this file\n",
    "using an editor (be sure to use the api.py file and not the compiled api.pyc binary\n",
    "file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\nltk\\\\tag\\\\api.py'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.tag.api.__file__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20\n",
    " Write code to search the Brown Corpus for particular words and phrases according to\n",
    "tags, to answer the following questions:\n",
    "1. Produce an alphabetically sorted list of the distinct words tagged as MD.\n",
    "2. Identify words that can be plural nouns or third person singular verbs (e.g. deals,\n",
    "flies).\n",
    "3. Identify three-word prepositional phrases of the form IN + DET + NN (eg. in the\n",
    "lab).\n",
    "4. What is the ratio of masculine to feminine pronouns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "tagged_words = brown.tagged_words(categories=[\"learned\", \"news\", \"fiction\"])\n",
    "MD_list = sorted(set(w for (w, t) in tagged_words if t == \"MD\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Can', 'Could', 'Should', 'Will', 'Would', 'can', 'could', 'may', 'might', 'must', 'need', 'ought', 'shall', 'should', 'will', 'would']\n"
     ]
    }
   ],
   "source": [
    "print(MD_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answers\n",
      "stands\n",
      "shows\n",
      "services\n",
      "needs\n",
      "means\n",
      "plans\n",
      "remains\n",
      "bars\n",
      "points\n",
      "calls\n",
      "numbers\n",
      "states\n",
      "costs\n",
      "moves\n",
      "approaches\n",
      "lives\n",
      "lists\n",
      "strikes\n",
      "hopes\n",
      "marks\n",
      "ends\n",
      "wonders\n",
      "causes\n",
      "runs\n",
      "plays\n",
      "colors\n",
      "stems\n",
      "works\n",
      "snatches\n",
      "leaves\n",
      "faces\n",
      "wishes\n",
      "passes\n",
      "acts\n",
      "subjects\n",
      "clouds\n",
      "estimates\n"
     ]
    }
   ],
   "source": [
    "ends_s = [(w, t) for (w, t) in tagged_words if w.endswith(\"s\")]\n",
    "cfd = nltk.ConditionalFreqDist(ends_s)\n",
    "for word in cfd.conditions():\n",
    "    if \"VBZ\" in cfd[word] and \"NNS\" in cfd[word]:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (w1, t1), (w2, t2), (w3, t3) in nltk.trigrams(tagged_words):\n",
    "    if t1 == \"IN\" and t2 == \"DET\" and t3 == \"NN\":\n",
    "        print(w1, w2, w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion of masculine to feminine is 373%\n"
     ]
    }
   ],
   "source": [
    "tagged_words = [(w.lower(), t) for w, t in tagged_words]\n",
    "male = [w for w, t in tagged_words if w in [\"he\", \"his\", \"him\", \"himself\"]]\n",
    "female = [w for w, t in tagged_words if w in [\"she\", \"her\", \"herself\"]]\n",
    "print(\"proportion of masculine to feminine is {:.0%}\".format(len(male)/len(female)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 21\n",
    " In 3.1 we saw a table involving frequency counts for the verbs adore, love, like, prefer\n",
    "and preceding qualifiers absolutely and definitely. Investigate the full range of adverbs\n",
    "that appear before these four verbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       like love \n",
      "always    1    0 \n",
      "dearly    0    1 \n",
      "simply    1    0 \n"
     ]
    }
   ],
   "source": [
    "cfd = nltk.ConditionalFreqDist([(w1, w2) for (w1, t1), (w2, t2) in nltk.bigrams(tagged_words) \n",
    "                                if w2 in ['adore', 'love', 'like', 'prefer'] and t1 == \"RB\" and t2.startswith(\"VB\")])\n",
    "cfd.tabulate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 22\n",
    " We defined the regexp_tagger that can be used as a fall-back tagger for unknown\n",
    "words. This tagger only checks for cardinal numbers. By testing for particular prefix or\n",
    "suffix strings, it should be possible to guess other tags. For example, we could tag any\n",
    "word that ends with -s as a plural noun. Define a regular expression tagger (using\n",
    "RegexpTagger()) that tests for at least five other patterns in the spelling of words. (Use\n",
    "inline documentation to explain the rules.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [(r\".+ion$\", \"NN\"),\n",
    "            (r\".+ly$\", \"RB\"), \n",
    "            (r\".+ous$\", \"JJ\"),\n",
    "            (r\".+ify$\", \"VB\"),\n",
    "            (r\".+s$\", \"NNS\")]\n",
    "reg_tagger = nltk.RegexpTagger(patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 23\n",
    "Consider the regular expression tagger developed in the exercises in the previous\n",
    "section. Evaluate the tagger using its accuracy() method, and try to come up with ways to\n",
    "improve its performance. Discuss your findings. How does objective evaluation help in\n",
    "the development process?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.889796117135251"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sents = brown.tagged_sents(categories=[\"learned\", \"news\", \"fiction\"])\n",
    "test_sents = brown.tagged_sents(categories=\"editorial\")\n",
    "t0 = nltk.DefaultTagger(\"NN\")\n",
    "t1 = nltk.RegexpTagger(patterns, backoff=t0)\n",
    "t2 = nltk.UnigramTagger(tagged_sents, backoff=t1)\n",
    "t3 = nltk.BigramTagger(tagged_sents, backoff=t2)\n",
    "t3.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 24\n",
    " How serious is the sparse data problem? Investigate the performance of n-gram taggers\n",
    "as n increases from 1 to 6. Tabulate the accuracy score. Estimate the training data\n",
    "required for these taggers, assuming a vocabulary size of 10 5 and a tagset size of 10 2 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = nltk.DefaultTagger(\"NN\")\n",
    "t1 = nltk.UnigramTagger(tagged_sents, backoff=t0)\n",
    "t2 = nltk.BigramTagger(tagged_sents, backoff=t1)\n",
    "t3 = nltk.TrigramTagger(tagged_sents, backoff=t2)\n",
    "t4 = nltk.NgramTagger(4, tagged_sents, backoff=t3)\n",
    "t5 = nltk.NgramTagger(5, tagged_sents, backoff=t4)\n",
    "t6 = nltk.NgramTagger(6, tagged_sents, backoff=t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 Accuracy: 0.8689533147198234\n",
      "t2 Accuracy: 0.8820855788585157\n",
      "t3 Accuracy: 0.8818096227517693\n",
      "t4 Accuracy: 0.8803486786572301\n",
      "t5 Accuracy: 0.8798779300045452\n",
      "t6 Accuracy: 0.8796993701707682\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 7):\n",
    "    print(\"t\" + str(i) + \" Accuracy: \" + str(eval(\"t\" + str(i) + \".evaluate(test_sents)\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 25\n",
    "Obtain some tagged data for another language, and train and evaluate a variety of\n",
    "taggers on it. If the language is morphologically complex, or if there are any orthographic\n",
    "clues (e.g. capitalization) to word classes, consider developing a regular expression\n",
    "tagger for it (ordered after the unigram tagger, and before the default tagger). How does\n",
    "the accuracy of your tagger(s) compare with the same taggers run on English data?\n",
    "Discuss any issues you encounter in applying these methods to the language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 26\n",
    "4.1 plotted a curve showing change in the performance of a lookup tagger as the model\n",
    "size was increased. Plot the performance curve for a unigram tagger, as the amount of\n",
    "training data is varied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_tagger = nltk.UnigramTagger(tagged_sents)\n",
    "score = []\n",
    "sents = []\n",
    "for category in brown.categories()[:-1]:\n",
    "    sents += brown.tagged_sents(categories=category)\n",
    "    tagger = nltk.UnigramTagger(sents)\n",
    "    score.append(tagger.evaluate(brown.tagged_sents(categories=brown.categories()[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(score)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 27\n",
    " Inspect the confusion matrix for the bigram tagger t2 defined in 5, and identify one or\n",
    "more sets of tags to collapse. Define a dictionary to do the mapping, and evaluate the\n",
    "tagger on the simplified data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "tagged_words = brown.tagged_words(categories=[\"news\", \"editorial\", \"fiction\"])\n",
    "words = [word for (word, tag) in tagged_words]\n",
    "test_tags = [tag for word, tag in t2.tag(words)]\n",
    "gold_tags = [tag for word, tag in tagged_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 28\n",
    "Experiment with taggers using the simplified tagset (or make one of your own by\n",
    "discarding all but the first character of each tag name). Such a tagger has fewer\n",
    "distinctions to make, but much less information on which to base its work. Discuss your\n",
    "findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 29\n",
    "Recall the example of a bigram tagger which encountered a word it hadn't seen during\n",
    "training, and tagged the rest of the sentence as None. It is possible for a bigram tagger to\n",
    "fail part way through a sentence even if it contains no unseen words (even if the sentence\n",
    "was used during training). In what circumstance can this happen? Can you write a\n",
    "program to find some examples of this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The case where some words do not appear as a pair as seen in training sets\n"
     ]
    }
   ],
   "source": [
    "print(\"The case where some words do not appear as a pair as seen in training sets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30\n",
    " Preprocess the Brown News data by replacing low frequency words with UNK, but\n",
    "leaving the tags untouched. Now train and evaluate a bigram tagger on this data. How\n",
    "much does this help? What is the contribution of the unigram tagger and default tagger\n",
    "now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07273878319589637"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = defaultdict(lambda: \"UNK\")\n",
    "tagged_sents = brown.tagged_sents(categories='news')\n",
    "fd = nltk.FreqDist(w for sent in tagged_sents for w, t in sent)\n",
    "for w, _ in fd.most_common(1000):\n",
    "    mapping[w] = w\n",
    "replaced = [[(mapping[w], t) for w, t in sent] for sent in tagged_sents]\n",
    "t2 = nltk.BigramTagger(replaced)\n",
    "t2.evaluate(brown.tagged_sents(categories='editorial'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7211869359132523"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = nltk.DefaultTagger(\"NN\")\n",
    "t1 = nltk.UnigramTagger(replaced, backoff=t0)\n",
    "t2 = nltk.BigramTagger(replaced, backoff=t1)\n",
    "t2.evaluate(brown.tagged_sents(categories='editorial'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 31\n",
    " Modify the program in 4.1 to use a logarithmic scale on the x-axis, by replacing\n",
    "pylab.plot() with pylab.semilogx(). What do you notice about the shape of the resulting\n",
    "plot? Does the gradient tell you anything?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(cfd, wordlist):\n",
    "    lt = dict((word, cfd[word].max()) for word in wordlist)\n",
    "    baseline_tagger = nltk.UnigramTagger(model=lt, backoff=nltk.DefaultTagger('NN'))\n",
    "    return baseline_tagger.evaluate(brown.tagged_sents(categories='news'))\n",
    "\n",
    "def display():\n",
    "    import pylab\n",
    "    word_freqs = nltk.FreqDist(brown.words(categories='news')).most_common()\n",
    "    words_by_freq = [w for (w, _) in word_freqs]\n",
    "    cfd = nltk.ConditionalFreqDist(brown.tagged_words(categories='news'))\n",
    "    sizes = map(int, pylab.log(pylab.arange(1, 16384)))\n",
    "    perfs = [performance(cfd, words_by_freq[:size]) for size in sizes]\n",
    "    pylab.plot(sizes, perfs, '-bo')\n",
    "    pylab.title('Lookup Tagger Performance with Varying Model Size')\n",
    "    pylab.xlabel('Model Size')\n",
    "    pylab.ylabel('Performance')\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45578495136941344"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "brown_sents = brown.sents(categories='news')\n",
    "\n",
    "fd = nltk.FreqDist(brown.words(categories='news'))\n",
    "cfd = nltk.ConditionalFreqDist(brown.tagged_words(categories='news'))\n",
    "most_freq_words = fd.most_common(100)\n",
    "likely_tags = dict((word, cfd[word].max()) for (word, _) in most_freq_words)\n",
    "baseline_tagger = nltk.UnigramTagger(model=likely_tags)\n",
    "baseline_tagger.evaluate(brown_tagged_sents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
